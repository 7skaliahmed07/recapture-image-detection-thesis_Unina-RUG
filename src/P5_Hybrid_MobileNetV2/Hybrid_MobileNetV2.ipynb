{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, Concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Step 1: Define paths and hyperparameters\n",
        "DATA_ROOT = \"/content/drive/MyDrive/NTU-Roselab-Dataset\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "N_FOLDS = 5\n",
        "MODEL_NAME = \"Hybrid_MobileNetV2\"\n",
        "OUTPUT_DIR = f\"/content/drive/MyDrive/Recapture_Photo_Detection/{MODEL_NAME}/results\"\n",
        "SPLIT_DIR = \"/content/drive/MyDrive/Recapture_Photo_Detection\"\n",
        "CHECKPOINT_FILE = f\"{OUTPUT_DIR}/checkpoint.json\"\n",
        "PREPROCESSING = \"Fourier_Laplacian\"\n",
        "HYPERPARAMETERS = {\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"n_folds\": N_FOLDS,\n",
        "    \"dropout_rate\": 0.4\n",
        "}\n",
        "\n",
        "# Step 2: Mount Google Drive and verify dataset path\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except ImportError:\n",
        "    raise ImportError(\"This script must be run in Google Colab with Google Drive mounted.\")\n",
        "if not os.path.exists(DATA_ROOT):\n",
        "    raise FileNotFoundError(f\"Dataset directory {DATA_ROOT} does not exist. Please check the path.\")\n",
        "\n",
        "# Step 3: Check dataset balance\n",
        "def check_dataset_balance(data_root):\n",
        "    originals_path = os.path.join(data_root, 'originals')\n",
        "    recaptures_path = os.path.join(data_root, 'recaptures')\n",
        "    originals_count = sum(len(files) for _, _, files in os.walk(originals_path))\n",
        "    recaptures_count = sum(len(files) for _, _, files in os.walk(recaptures_path))\n",
        "    print(f\"Dataset Balance: {originals_count} originals, {recaptures_count} recaptures\")\n",
        "    return originals_count, recaptures_count\n",
        "\n",
        "originals_count, recaptures_count = check_dataset_balance(DATA_ROOT)\n",
        "\n",
        "# Step 4: Define Hann window function\n",
        "@tf.function\n",
        "def hann2d(h, w):\n",
        "    hann1 = tf.signal.hann_window(h, periodic=True)\n",
        "    hann2 = tf.signal.hann_window(w, periodic=True)\n",
        "    return tf.sqrt(tf.tensordot(hann1, hann2, axes=0))\n",
        "\n",
        "# Step 5: Define hybrid preprocessing function\n",
        "@tf.function\n",
        "def hybrid_preprocess(img, label):\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    gray = tf.image.rgb_to_grayscale(img)\n",
        "    gray = tf.cast(gray, tf.float32)\n",
        "\n",
        "    # FFT branch\n",
        "    fft_img = gray - tf.reduce_mean(gray)\n",
        "    hann_window = hann2d(IMG_SIZE, IMG_SIZE)\n",
        "    fft_img *= hann_window\n",
        "    fft = tf.signal.fft2d(tf.complex(fft_img[..., 0], 0.0))\n",
        "    fft = tf.signal.fftshift(fft)\n",
        "    spectrum = tf.math.log1p(tf.abs(fft))\n",
        "    spectrum = (spectrum - tf.reduce_mean(spectrum)) / (tf.math.reduce_std(spectrum) + 1e-6)\n",
        "    spectrum = (spectrum - tf.reduce_min(spectrum)) / (tf.reduce_max(spectrum) - tf.reduce_min(spectrum) + 1e-6)\n",
        "    fft_stack = tf.stack([spectrum, spectrum, spectrum], axis=-1)\n",
        "\n",
        "    # Laplacian branch\n",
        "    gray_n = (gray - tf.reduce_min(gray)) / (tf.reduce_max(gray) - tf.reduce_min(gray) + 1e-6)\n",
        "    lap = tf.image.sobel_edges(gray)  # Shape: (batch, h, w, 1, 2)\n",
        "    lap = tf.sqrt(tf.reduce_sum(tf.square(lap), axis=-1))  # Shape: (batch, h, w, 1)\n",
        "    lap = tf.squeeze(lap, axis=-1)  # Shape: (batch, h, w)\n",
        "    lap = (lap - tf.reduce_mean(lap)) / (tf.math.reduce_std(lap) + 1e-6)\n",
        "    lap = (lap - tf.reduce_min(lap)) / (tf.reduce_max(lap) - tf.reduce_min(lap) + 1e-6)\n",
        "    lap_stack = tf.stack([gray_n[..., 0], lap, lap], axis=-1)  # Shape: (batch, h, w, 3)\n",
        "\n",
        "    return (fft_stack, lap_stack), label\n",
        "\n",
        "# Step 6: Define custom rotation function\n",
        "@tf.function\n",
        "def random_rotation(img, max_angle=0.1):  # max_angle in radians (~10 degrees)\n",
        "    angles = [0, np.pi/2, np.pi, 3*np.pi/2]  # 0°, 90°, 180°, 270°\n",
        "    k = tf.random.uniform(shape=(), minval=0, maxval=len(angles), dtype=tf.int32)\n",
        "    img = tf.image.rot90(img, k)\n",
        "    return img\n",
        "\n",
        "# Step 7: Define data augmentation\n",
        "@tf.function\n",
        "def augment_image(inputs, label):\n",
        "    fft_img, lap_img = inputs\n",
        "    fft_img = tf.image.random_flip_left_right(fft_img)\n",
        "    lap_img = tf.image.random_flip_left_right(lap_img)\n",
        "    fft_img = random_rotation(fft_img, max_angle=0.1)\n",
        "    lap_img = random_rotation(lap_img, max_angle=0.1)\n",
        "    return (fft_img, lap_img), label\n",
        "\n",
        "# Step 8: Load or create train-test split\n",
        "def load_or_create_split():\n",
        "    if all(os.path.exists(os.path.join(SPLIT_DIR, f)) for f in ['X_train.npy', 'X_test.npy', 'y_train.npy', 'y_test.npy']):\n",
        "        print(\"Loading existing train-test split...\")\n",
        "        X_train = np.load(os.path.join(SPLIT_DIR, 'X_train.npy'))\n",
        "        X_test = np.load(os.path.join(SPLIT_DIR, 'X_test.npy'))\n",
        "        y_train = np.load(os.path.join(SPLIT_DIR, 'y_train.npy'))\n",
        "        y_test = np.load(os.path.join(SPLIT_DIR, 'y_test.npy'))\n",
        "    else:\n",
        "        dataset = image_dataset_from_directory(\n",
        "            DATA_ROOT,\n",
        "            labels='inferred',\n",
        "            label_mode='binary',\n",
        "            image_size=(IMG_SIZE, IMG_SIZE),\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            seed=42\n",
        "        )\n",
        "        images, labels = [], []\n",
        "        for img_batch, label_batch in dataset:\n",
        "            images.append(img_batch.numpy())\n",
        "            labels.append(label_batch.numpy())\n",
        "        images = np.concatenate(images, axis=0)\n",
        "        labels = np.concatenate(labels, axis=0).flatten()\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            images, labels, test_size=0.2, stratify=labels, random_state=42\n",
        "        )\n",
        "\n",
        "        Path(SPLIT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "        np.save(os.path.join(SPLIT_DIR, 'X_train.npy'), X_train)\n",
        "        np.save(os.path.join(SPLIT_DIR, 'X_test.npy'), X_test)\n",
        "        np.save(os.path.join(SPLIT_DIR, 'y_train.npy'), y_train)\n",
        "        np.save(os.path.join(SPLIT_DIR, 'y_test.npy'), y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = load_or_create_split()\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).map(hybrid_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Step 9: Define function to create two-branch MobileNetV2 model\n",
        "def create_model():\n",
        "    fft_in = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='fft_input')\n",
        "    lap_in = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='lap_input')\n",
        "\n",
        "    # FFT branch wrapped in Sequential with unique name\n",
        "    fft_base = Sequential([\n",
        "        MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    ], name='fft_mobilenetv2')\n",
        "    for layer in fft_base.layers[0].layers[:-20]:\n",
        "        layer.trainable = False\n",
        "    fft_x = GlobalAveragePooling2D()(fft_base(fft_in))\n",
        "\n",
        "    # Laplacian branch wrapped in Sequential with unique name\n",
        "    lap_base = Sequential([\n",
        "        MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    ], name='lap_mobilenetv2')\n",
        "    for layer in lap_base.layers[0].layers[:-20]:\n",
        "        layer.trainable = False\n",
        "    lap_x = GlobalAveragePooling2D()(lap_base(lap_in))\n",
        "\n",
        "    # Merge branches\n",
        "    merged = Concatenate()([fft_x, lap_x])\n",
        "    x = Dropout(HYPERPARAMETERS['dropout_rate'])(merged)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=[fft_in, lap_in], outputs=out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 10: Convert NumPy types to JSON-serializable types\n",
        "def convert_to_serializable(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    return obj\n",
        "\n",
        "# Step 11: Define function to save results\n",
        "def save_model_results(model, dataset, history, model_name, output_dir, fold=None, preprocessing='None', hyperparameters=None):\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    fold_str = f\"_fold_{fold}\" if fold is not None else \"\"\n",
        "\n",
        "    # Evaluate on dataset\n",
        "    y_true, y_pred = [], []\n",
        "    for (fft_imgs, lap_imgs), labels in dataset:\n",
        "        preds = (model.predict([fft_imgs, lap_imgs], verbose=0) > 0.5).astype(int)\n",
        "        y_true.extend(labels.numpy().astype(int))\n",
        "        y_pred.extend(preds.flatten())\n",
        "\n",
        "    # Check prediction distribution\n",
        "    originals_pred = sum(1 for p in y_pred if p == 0)\n",
        "    recaptures_pred = sum(1 for p in y_pred if p == 1)\n",
        "    print(f\"Predictions {fold_str}: {originals_pred} originals, {recaptures_pred} recaptures\")\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_true, y_pred, target_names=['originals', 'recaptured'], output_dict=True)\n",
        "    class_report_df = pd.DataFrame(class_report).transpose()\n",
        "    class_report_df.to_csv(f'{output_dir}/{model_name}_classification_report{fold_str}.csv')\n",
        "\n",
        "    # Confusion matrix (detailed)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['originals', 'recaptured'], yticklabels=['originals', 'recaptured'])\n",
        "    plt.title(f'Confusion Matrix - {model_name}{fold_str}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save confusion matrix as CSV\n",
        "    cm_df = pd.DataFrame(cm, index=['True_originals', 'True_recaptured'], columns=['Pred_originals', 'Pred_recaptured'])\n",
        "    cm_df.to_csv(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.csv')\n",
        "\n",
        "    # Model summary (only for final model)\n",
        "    if fold is None:\n",
        "        summary_file = f'{output_dir}/{model_name}_summary.txt'\n",
        "        with open(summary_file, 'w') as f:\n",
        "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "    # Calculate total and trainable parameters\n",
        "    total_params = model.count_params()\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "    # Aggregate results\n",
        "    results = {\n",
        "        'Model': model_name,\n",
        "        'Preprocessing': preprocessing,\n",
        "        'Accuracy': class_report['accuracy'],\n",
        "        'Total_Parameters': total_params,\n",
        "        'Trainable_Parameters': trainable_params,\n",
        "        'Fold': fold if fold is not None else 'Final'\n",
        "    }\n",
        "    if hyperparameters:\n",
        "        results.update(hyperparameters)\n",
        "    for label, metrics in class_report.items():\n",
        "        if isinstance(metrics, dict):\n",
        "            results.update({\n",
        "                f'Precision_{label}': metrics['precision'],\n",
        "                f'Recall_{label}': metrics['recall'],\n",
        "                f'F1-Score_{label}': metrics['f1-score'],\n",
        "                f'Support_{label}': metrics['support']\n",
        "            })\n",
        "\n",
        "    # Convert NumPy types to JSON-serializable types\n",
        "    results = {k: convert_to_serializable(v) for k, v in results.items()}\n",
        "\n",
        "    # Save results to JSON\n",
        "    with open(f'{output_dir}/{model_name}_results{fold_str}.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    # Plot and save accuracy/loss curves\n",
        "    if history is not None:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        if 'val_accuracy' in history.history:\n",
        "            plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'Accuracy Curve - {model_name}{fold_str}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "        if 'val_loss' in history.history:\n",
        "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title(f'Loss Curve - {model_name}{fold_str}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_dir}/{model_name}_accuracy_loss_curve{fold_str}.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Save full model for final model (using .keras format)\n",
        "    if fold is None:\n",
        "        model.save(f'{output_dir}/{model_name}_model.keras', overwrite=True)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Step 12: Checkpointing and resumption logic\n",
        "def load_checkpoint():\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        with open(CHECKPOINT_FILE, 'r') as f:\n",
        "            checkpoint = json.load(f)\n",
        "        last_completed_fold = checkpoint.get('last_completed_fold', 0)\n",
        "        print(f\"Resuming from checkpoint: Last completed fold = {last_completed_fold}\")\n",
        "        return last_completed_fold\n",
        "    return 0\n",
        "\n",
        "def save_checkpoint(fold):\n",
        "    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    checkpoint = {'last_completed_fold': fold}\n",
        "    with open(CHECKPOINT_FILE, 'w') as f:\n",
        "        json.dump(checkpoint, f, indent=4)\n",
        "\n",
        "# Step 13: Perform 5-fold cross-validation with checkpointing\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "fold_results = []\n",
        "last_completed_fold = load_checkpoint()\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    if fold <= last_completed_fold:\n",
        "        print(f\"Skipping fold {fold} (already completed)\")\n",
        "        # Load results from previous run\n",
        "        fold_str = f\"_fold_{fold}\"\n",
        "        result_file = f'{OUTPUT_DIR}/{MODEL_NAME}_results{fold_str}.json'\n",
        "        if os.path.exists(result_file):\n",
        "            with open(result_file, 'r') as f:\n",
        "                fold_results.append(json.load(f))\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nTraining Fold {fold}/{N_FOLDS}\")\n",
        "\n",
        "    # Create train and validation datasets for this fold\n",
        "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_fold_train, y_fold_train)).batch(BATCH_SIZE).map(hybrid_preprocess).map(augment_image).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_fold_val, y_fold_val)).batch(BATCH_SIZE).map(hybrid_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Create model and load weights if available\n",
        "    model = create_model()\n",
        "    fold_str = f\"_fold_{fold}\"\n",
        "    checkpoint_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model{fold_str}.weights.h5'\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading weights for fold {fold} from {checkpoint_path}\")\n",
        "        model.load_weights(checkpoint_path)\n",
        "\n",
        "    # Train model with early stopping and checkpointing\n",
        "    checkpoint_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, class_weight={0: 1.0, 1: 1.5}, verbose=1, callbacks=[early_stopping, checkpoint_callback])\n",
        "\n",
        "    # Save results for this fold\n",
        "    results = save_model_results(\n",
        "        model, val_ds, history, MODEL_NAME, OUTPUT_DIR,\n",
        "        fold=fold, preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n",
        "    )\n",
        "    fold_results.append(results)\n",
        "\n",
        "    # Update checkpoint\n",
        "    save_checkpoint(fold)\n",
        "\n",
        "# Step 14: Train final model on full training set if not already done\n",
        "if last_completed_fold < N_FOLDS + 1:\n",
        "    print(\"\\nTraining final model on full training set\")\n",
        "    final_model_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model.keras'\n",
        "    if os.path.exists(final_model_path) and last_completed_fold == 'final':\n",
        "        print(f\"Final model already saved at {final_model_path}, skipping training\")\n",
        "        # Load results from previous run\n",
        "        result_file = f'{OUTPUT_DIR}/{MODEL_NAME}_results.json'\n",
        "        if os.path.exists(result_file):\n",
        "            with open(result_file, 'r') as f:\n",
        "                results = json.load(f)\n",
        "            print(f\"Final Results for {MODEL_NAME}:\", results)\n",
        "    else:\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE).map(hybrid_preprocess).map(augment_image).prefetch(tf.data.AUTOTUNE)\n",
        "        model = create_model()\n",
        "        checkpoint_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model.weights.h5'\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            print(f\"Loading weights for final model from {checkpoint_path}\")\n",
        "            model.load_weights(checkpoint_path)\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(checkpoint_path, monitor='loss', save_best_only=True, save_weights_only=True)\n",
        "        history = model.fit(train_ds, epochs=EPOCHS, class_weight={0: 1.0, 1: 1.5}, verbose=1, callbacks=[checkpoint_callback])\n",
        "\n",
        "        # Save results for final model\n",
        "        results = save_model_results(\n",
        "            model, test_ds, history, MODEL_NAME, OUTPUT_DIR,\n",
        "            preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n",
        "        )\n",
        "        print(f\"Final Results for {MODEL_NAME}:\", results)\n",
        "\n",
        "        # Update checkpoint\n",
        "        save_checkpoint('final')\n",
        "\n",
        "# Step 15: Aggregate cross-validation results\n",
        "if fold_results:\n",
        "    fold_df = pd.DataFrame(fold_results)\n",
        "    mean_results = {\n",
        "        'Model': MODEL_NAME,\n",
        "        'Preprocessing': PREPROCESSING,\n",
        "        'Mean_Accuracy': fold_df['Accuracy'].mean(),\n",
        "        'Std_Accuracy': fold_df['Accuracy'].std(),\n",
        "        'Mean_Precision_recaptured': fold_df['Precision_recaptured'].mean(),\n",
        "        'Mean_Recall_recaptured': fold_df['Recall_recaptured'].mean(),\n",
        "        'Mean_F1-Score_recaptured': fold_df['F1-Score_recaptured'].mean(),\n",
        "        'Mean_Total_Parameters': fold_df['Total_Parameters'].mean(),\n",
        "        'Mean_Trainable_Parameters': fold_df['Trainable_Parameters'].mean()\n",
        "    }\n",
        "    # Convert NumPy types in mean_results\n",
        "    mean_results = {k: convert_to_serializable(v) for k, v in mean_results.items()}\n",
        "    with open(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_summary.json', 'w') as f:\n",
        "        json.dump(mean_results, f, indent=4)\n",
        "    fold_df.to_csv(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_results.csv', index=False)\n",
        "    print(\"\\nCross-Validation Summary:\", mean_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "a2W-zTx45e4S",
        "outputId": "169b5c52-7bd3-4162-d60c-027f69d43cd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Balance: 1202 originals, 1199 recaptures\n",
            "Loading existing train-test split...\n",
            "Resuming from checkpoint: Last completed fold = 5\n",
            "Skipping fold 1 (already completed)\n",
            "Skipping fold 2 (already completed)\n",
            "Skipping fold 3 (already completed)\n",
            "Skipping fold 4 (already completed)\n",
            "Skipping fold 5 (already completed)\n",
            "\n",
            "Training final model on full training set\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Loading weights for final model from /content/drive/MyDrive/Recapture_Photo_Detection/Hybrid_MobileNetV2/results/Hybrid_MobileNetV2_model.weights.h5\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 94 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 2s/step - accuracy: 0.9809 - loss: 0.0732\n",
            "Epoch 2/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 0.0468\n",
            "Epoch 3/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 2s/step - accuracy: 0.9874 - loss: 0.0408\n",
            "Epoch 4/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step - accuracy: 0.9910 - loss: 0.0337\n",
            "Epoch 5/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 3s/step - accuracy: 0.9896 - loss: 0.0399\n",
            "Epoch 6/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 2s/step - accuracy: 0.9873 - loss: 0.0569\n",
            "Epoch 7/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 2s/step - accuracy: 0.9908 - loss: 0.0306\n",
            "Epoch 8/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0210\n",
            "Predictions : 158 originals, 323 recaptures\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Results for Hybrid_MobileNetV2: {'Model': 'Hybrid_MobileNetV2', 'Preprocessing': 'Fourier_Laplacian', 'Accuracy': 0.8066528066528067, 'Total_Parameters': 4843905, 'Trainable_Parameters': 2740097, 'Fold': 'Final', 'learning_rate': 0.0001, 'batch_size': 16, 'optimizer': 'Adam', 'epochs': 8, 'n_folds': 5, 'dropout_rate': 0.4, 'Precision_originals': 0.9683544303797469, 'Recall_originals': 0.6348547717842323, 'F1-Score_originals': 0.7669172932330827, 'Support_originals': 241.0, 'Precision_recaptured': 0.7275541795665634, 'Recall_recaptured': 0.9791666666666666, 'F1-Score_recaptured': 0.8348134991119005, 'Support_recaptured': 240.0, 'Precision_macro avg': 0.8479543049731552, 'Recall_macro avg': 0.8070107192254494, 'F1-Score_macro avg': 0.8008653961724916, 'Support_macro avg': 481.0, 'Precision_weighted avg': 0.8482046170841875, 'Recall_weighted avg': 0.8066528066528067, 'F1-Score_weighted avg': 0.8007948179959024, 'Support_weighted avg': 481.0}\n",
            "\n",
            "Cross-Validation Summary: {'Model': 'Hybrid_MobileNetV2', 'Preprocessing': 'Fourier_Laplacian', 'Mean_Accuracy': 0.7375, 'Std_Accuracy': 0.0798294963087127, 'Mean_Precision_recaptured': 0.7655914038673717, 'Mean_Recall_recaptured': 0.6915030541012216, 'Mean_F1-Score_recaptured': 0.712979149907168, 'Mean_Total_Parameters': 4843905.0, 'Mean_Trainable_Parameters': 2740097.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tN9MirDD5fxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}