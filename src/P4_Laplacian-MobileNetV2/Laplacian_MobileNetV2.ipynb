{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hvRNebBPv4ZV",
        "outputId": "59c1f408-1f72-49a7-ea32-c6b084f9fa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Balance: 1202 originals, 1199 recaptures\n",
            "Found 2401 files belonging to 2 classes.\n",
            "\n",
            "Training Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5907 - loss: 0.7342 - val_accuracy: 0.6771 - val_loss: 0.6037\n",
            "Epoch 2/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.8605 - loss: 0.3345 - val_accuracy: 0.7240 - val_loss: 0.5893\n",
            "Epoch 3/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.9383 - loss: 0.1954 - val_accuracy: 0.7526 - val_loss: 0.5738\n",
            "Epoch 4/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9763 - loss: 0.1059 - val_accuracy: 0.7552 - val_loss: 0.5821\n",
            "Epoch 5/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.9927 - loss: 0.0525 - val_accuracy: 0.7708 - val_loss: 0.5831\n",
            "Epoch 6/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0277 - val_accuracy: 0.7734 - val_loss: 0.6158\n",
            "Predictions _fold_1: 179 originals, 205 recaptures\n",
            "\n",
            "Training Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 1s/step - accuracy: 0.5930 - loss: 0.7266 - val_accuracy: 0.7240 - val_loss: 0.5540\n",
            "Epoch 2/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8688 - loss: 0.3380 - val_accuracy: 0.7656 - val_loss: 0.5117\n",
            "Epoch 3/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 1s/step - accuracy: 0.9533 - loss: 0.1900 - val_accuracy: 0.7865 - val_loss: 0.5245\n",
            "Epoch 4/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.9840 - loss: 0.1048 - val_accuracy: 0.7839 - val_loss: 0.5149\n",
            "Epoch 5/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.9959 - loss: 0.0494 - val_accuracy: 0.7969 - val_loss: 0.5191\n",
            "Predictions _fold_2: 178 originals, 206 recaptures\n",
            "\n",
            "Training Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - accuracy: 0.5857 - loss: 0.7362 - val_accuracy: 0.5573 - val_loss: 0.9713\n",
            "Epoch 2/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.8558 - loss: 0.3482 - val_accuracy: 0.5833 - val_loss: 1.0602\n",
            "Epoch 3/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9405 - loss: 0.1914 - val_accuracy: 0.5495 - val_loss: 1.4236\n",
            "Epoch 4/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.9691 - loss: 0.1177 - val_accuracy: 0.5651 - val_loss: 1.5519\n",
            "Predictions _fold_3: 360 originals, 24 recaptures\n",
            "\n",
            "Training Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 1s/step - accuracy: 0.6267 - loss: 0.7139 - val_accuracy: 0.5833 - val_loss: 0.7695\n",
            "Epoch 2/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8659 - loss: 0.3393 - val_accuracy: 0.6042 - val_loss: 0.8325\n",
            "Epoch 3/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9410 - loss: 0.1889 - val_accuracy: 0.6615 - val_loss: 0.7413\n",
            "Epoch 4/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.9854 - loss: 0.0967 - val_accuracy: 0.7188 - val_loss: 0.6007\n",
            "Epoch 5/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - accuracy: 0.9932 - loss: 0.0533 - val_accuracy: 0.7708 - val_loss: 0.5029\n",
            "Epoch 6/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.9991 - loss: 0.0265 - val_accuracy: 0.7891 - val_loss: 0.4881\n",
            "Epoch 7/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.8047 - val_loss: 0.4550\n",
            "Epoch 8/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.8151 - val_loss: 0.4149\n",
            "Predictions _fold_4: 205 originals, 179 recaptures\n",
            "\n",
            "Training Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - accuracy: 0.5804 - loss: 0.7507 - val_accuracy: 0.6484 - val_loss: 0.7035\n",
            "Epoch 2/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.8872 - loss: 0.3225 - val_accuracy: 0.6979 - val_loss: 0.6676\n",
            "Epoch 3/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.9510 - loss: 0.1959 - val_accuracy: 0.7526 - val_loss: 0.5277\n",
            "Epoch 4/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.9796 - loss: 0.1101 - val_accuracy: 0.7865 - val_loss: 0.4836\n",
            "Epoch 5/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0502 - val_accuracy: 0.7917 - val_loss: 0.5191\n",
            "Epoch 6/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0286 - val_accuracy: 0.8099 - val_loss: 0.4789\n",
            "Epoch 7/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8307 - val_loss: 0.4914\n",
            "Epoch 8/8\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8307 - val_loss: 0.5014\n",
            "Predictions _fold_5: 214 originals, 170 recaptures\n",
            "\n",
            "Training final model on full training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1142743286.py:109: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 886ms/step - accuracy: 0.5856 - loss: 0.7480\n",
            "Epoch 2/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 856ms/step - accuracy: 0.8743 - loss: 0.3242\n",
            "Epoch 3/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 894ms/step - accuracy: 0.9527 - loss: 0.1729\n",
            "Epoch 4/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 883ms/step - accuracy: 0.9883 - loss: 0.0860\n",
            "Epoch 5/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 887ms/step - accuracy: 0.9940 - loss: 0.0430\n",
            "Epoch 6/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 0.0202\n",
            "Epoch 7/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 944ms/step - accuracy: 1.0000 - loss: 0.0116\n",
            "Epoch 8/8\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 920ms/step - accuracy: 1.0000 - loss: 0.0074\n",
            "Predictions : 249 originals, 232 recaptures\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Results for Laplacian_MobileNetV2: {'Model': 'Laplacian_MobileNetV2', 'Preprocessing': 'Laplacian', 'Accuracy': 0.8461538461538461, 'Total_Parameters': 2259265, 'Trainable_Parameters': 1207361, 'Fold': 'Final', 'learning_rate': 0.0001, 'batch_size': 16, 'optimizer': 'Adam', 'epochs': 8, 'n_folds': 5, 'dropout_rate': 0.5, 'Precision_originals': 0.8353413654618473, 'Recall_originals': 0.8630705394190872, 'F1-Score_originals': 0.8489795918367347, 'Support_originals': 241.0, 'Precision_recaptured': 0.8577586206896551, 'Recall_recaptured': 0.8291666666666667, 'F1-Score_recaptured': 0.8432203389830508, 'Support_recaptured': 240.0, 'Precision_macro avg': 0.8465499930757512, 'Recall_macro avg': 0.8461186030428769, 'F1-Score_macro avg': 0.8460999654098927, 'Support_macro avg': 481.0, 'Precision_weighted avg': 0.8465266903156392, 'Recall_weighted avg': 0.8461538461538461, 'F1-Score_weighted avg': 0.8461059521592208, 'Support_weighted avg': 481.0}\n",
            "\n",
            "Cross-Validation Summary: {'Model': 'Laplacian_MobileNetV2', 'Preprocessing': 'Laplacian', 'Mean_Accuracy': 0.7401041666666666, 'Std_Accuracy': 0.10574007025057826, 'Mean_Precision_recaptured': 0.8255078330132053, 'Mean_Recall_recaptured': 0.6487020069808028, 'Mean_F1-Score_recaptured': 0.670789373962881, 'Mean_Total_Parameters': 2259265.0, 'Mean_Trainable_Parameters': 1207361.0}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Step 1: Define paths and hyperparameters\n",
        "DATA_ROOT = \"/content/drive/MyDrive/NTU-Roselab-Dataset\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "N_FOLDS = 5\n",
        "MODEL_NAME = \"Laplacian_MobileNetV2\"\n",
        "OUTPUT_DIR = f\"/content/drive/MyDrive/Recapture_Photo_Detection/{MODEL_NAME}/results\"\n",
        "SPLIT_DIR = \"/content/drive/MyDrive/Recapture_Photo_Detection\"\n",
        "PREPROCESSING = \"Laplacian\"\n",
        "HYPERPARAMETERS = {\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"n_folds\": N_FOLDS,\n",
        "    \"dropout_rate\": 0.5\n",
        "}\n",
        "\n",
        "# Step 2: Mount Google Drive and verify dataset path\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except ImportError:\n",
        "    raise ImportError(\"This script must be run in Google Colab with Google Drive mounted.\")\n",
        "if not os.path.exists(DATA_ROOT):\n",
        "    raise FileNotFoundError(f\"Dataset directory {DATA_ROOT} does not exist. Please check the path.\")\n",
        "\n",
        "# Step 3: Check dataset balance\n",
        "def check_dataset_balance(data_root):\n",
        "    originals_path = os.path.join(data_root, 'originals')\n",
        "    recaptures_path = os.path.join(data_root, 'recaptures')\n",
        "    originals_count = sum(len(files) for _, _, files in os.walk(originals_path))\n",
        "    recaptures_count = sum(len(files) for _, _, files in os.walk(recaptures_path))\n",
        "    print(f\"Dataset Balance: {originals_count} originals, {recaptures_count} recaptures\")\n",
        "    return originals_count, recaptures_count\n",
        "\n",
        "originals_count, recaptures_count = check_dataset_balance(DATA_ROOT)\n",
        "\n",
        "# Step 4: Define Laplacian preprocessing function\n",
        "@tf.function\n",
        "def laplacian_preprocess(img, label):\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    gray = tf.image.rgb_to_grayscale(img)\n",
        "    lap = tf.image.sobel_edges(gray)\n",
        "    lap = tf.reduce_sum(tf.square(lap), axis=-1)\n",
        "    lap = tf.sqrt(lap + 1e-6)\n",
        "    lap = tf.image.per_image_standardization(lap)\n",
        "    gray = tf.image.per_image_standardization(gray)\n",
        "    combined = tf.concat([gray, lap, lap], axis=-1)\n",
        "    return combined, label\n",
        "\n",
        "# Step 5: Load and split dataset (single train-test split)\n",
        "dataset = image_dataset_from_directory(\n",
        "    DATA_ROOT,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Convert dataset to NumPy arrays for cross-validation\n",
        "images, labels = [], []\n",
        "for img_batch, label_batch in dataset:\n",
        "    images.append(img_batch.numpy())\n",
        "    labels.append(label_batch.numpy())\n",
        "images = np.concatenate(images, axis=0)\n",
        "labels = np.concatenate(labels, axis=0).flatten()\n",
        "\n",
        "# Split into train (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Create directory for train-test split\n",
        "Path(SPLIT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save train-test split for consistency across models\n",
        "np.save(os.path.join(SPLIT_DIR, 'X_train.npy'), X_train)\n",
        "np.save(os.path.join(SPLIT_DIR, 'X_test.npy'), X_test)\n",
        "np.save(os.path.join(SPLIT_DIR, 'y_train.npy'), y_train)\n",
        "np.save(os.path.join(SPLIT_DIR, 'y_test.npy'), y_test)\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).map(laplacian_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Step 6: Define function to create MobileNetV2 model\n",
        "def create_model():\n",
        "    base = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    for layer in base.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dropout(HYPERPARAMETERS['dropout_rate'])(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(base.input, out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 7: Convert NumPy types to JSON-serializable types\n",
        "def convert_to_serializable(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    return obj\n",
        "\n",
        "# Step 8: Define function to save results\n",
        "def save_model_results(model, dataset, history, model_name, output_dir, fold=None, preprocessing='None', hyperparameters=None):\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    fold_str = f\"_fold_{fold}\" if fold is not None else \"\"\n",
        "\n",
        "    # Evaluate on dataset\n",
        "    y_true, y_pred = [], []\n",
        "    for imgs, labels in dataset:\n",
        "        preds = (model.predict(imgs, verbose=0) > 0.5).astype(int)\n",
        "        y_true.extend(labels.numpy().astype(int))\n",
        "        y_pred.extend(preds.flatten())\n",
        "\n",
        "    # Check prediction distribution\n",
        "    originals_pred = sum(1 for p in y_pred if p == 0)\n",
        "    recaptures_pred = sum(1 for p in y_pred if p == 1)\n",
        "    print(f\"Predictions {fold_str}: {originals_pred} originals, {recaptures_pred} recaptures\")\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_true, y_pred, target_names=['originals', 'recaptured'], output_dict=True)\n",
        "    class_report_df = pd.DataFrame(class_report).transpose()\n",
        "    class_report_df.to_csv(f'{output_dir}/{model_name}_classification_report{fold_str}.csv')\n",
        "\n",
        "    # Confusion matrix (detailed)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['originals', 'recaptured'], yticklabels=['originals', 'recaptured'])\n",
        "    plt.title(f'Confusion Matrix - {model_name}{fold_str}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save confusion matrix as CSV\n",
        "    cm_df = pd.DataFrame(cm, index=['True_originals', 'True_recaptured'], columns=['Pred_originals', 'Pred_recaptured'])\n",
        "    cm_df.to_csv(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.csv')\n",
        "\n",
        "    # Model summary (only for final model)\n",
        "    if fold is None:\n",
        "        summary_file = f'{output_dir}/{model_name}_summary.txt'\n",
        "        with open(summary_file, 'w') as f:\n",
        "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "    # Calculate total and trainable parameters\n",
        "    total_params = model.count_params()\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "    # Aggregate results\n",
        "    results = {\n",
        "        'Model': model_name,\n",
        "        'Preprocessing': preprocessing,\n",
        "        'Accuracy': class_report['accuracy'],\n",
        "        'Total_Parameters': total_params,\n",
        "        'Trainable_Parameters': trainable_params,\n",
        "        'Fold': fold if fold is not None else 'Final'\n",
        "    }\n",
        "    if hyperparameters:\n",
        "        results.update(hyperparameters)\n",
        "    for label, metrics in class_report.items():\n",
        "        if isinstance(metrics, dict):\n",
        "            results.update({\n",
        "                f'Precision_{label}': metrics['precision'],\n",
        "                f'Recall_{label}': metrics['recall'],\n",
        "                f'F1-Score_{label}': metrics['f1-score'],\n",
        "                f'Support_{label}': metrics['support']\n",
        "            })\n",
        "\n",
        "    # Convert NumPy types to JSON-serializable types\n",
        "    results = {k: convert_to_serializable(v) for k, v in results.items()}\n",
        "\n",
        "    # Save results to JSON\n",
        "    with open(f'{output_dir}/{model_name}_results{fold_str}.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    # Plot and save accuracy/loss curves\n",
        "    if history is not None:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "        if 'val_accuracy' in history.history:\n",
        "            plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'Accuracy Curve - {model_name}{fold_str}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "        if 'val_loss' in history.history:\n",
        "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title(f'Loss Curve - {model_name}{fold_str}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_dir}/{model_name}_accuracy_loss_curve{fold_str}.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Save model weights (only for final model)\n",
        "    if fold is None:\n",
        "        model.save(f'{output_dir}/{model_name}_model.h5')\n",
        "\n",
        "    return results\n",
        "\n",
        "# Step 9: Perform 5-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "fold_results = []\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f\"\\nTraining Fold {fold + 1}/{N_FOLDS}\")\n",
        "\n",
        "    # Create train and validation datasets for this fold\n",
        "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_fold_train, y_fold_train)).batch(BATCH_SIZE).map(laplacian_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_fold_val, y_fold_val)).batch(BATCH_SIZE).map(laplacian_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Create and train model with early stopping\n",
        "    model = create_model()\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "    # Save results for this fold\n",
        "    results = save_model_results(\n",
        "        model, val_ds, history, MODEL_NAME, OUTPUT_DIR,\n",
        "        fold=fold + 1, preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n",
        "    )\n",
        "    fold_results.append(results)\n",
        "\n",
        "# Step 10: Train final model on full training set\n",
        "print(\"\\nTraining final model on full training set\")\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE).map(laplacian_preprocess).prefetch(tf.data.AUTOTUNE)\n",
        "model = create_model()\n",
        "history = model.fit(train_ds, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "# Step 11: Evaluate final model on test set and save results\n",
        "results = save_model_results(\n",
        "    model, test_ds, history, MODEL_NAME, OUTPUT_DIR,\n",
        "    preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n",
        ")\n",
        "print(f\"Final Results for {MODEL_NAME}:\", results)\n",
        "\n",
        "# Step 12: Aggregate cross-validation results\n",
        "if fold_results:\n",
        "    fold_df = pd.DataFrame(fold_results)\n",
        "    mean_results = {\n",
        "        'Model': MODEL_NAME,\n",
        "        'Preprocessing': PREPROCESSING,\n",
        "        'Mean_Accuracy': fold_df['Accuracy'].mean(),\n",
        "        'Std_Accuracy': fold_df['Accuracy'].std(),\n",
        "        'Mean_Precision_recaptured': fold_df['Precision_recaptured'].mean(),\n",
        "        'Mean_Recall_recaptured': fold_df['Recall_recaptured'].mean(),\n",
        "        'Mean_F1-Score_recaptured': fold_df['F1-Score_recaptured'].mean(),\n",
        "        'Mean_Total_Parameters': fold_df['Total_Parameters'].mean(),\n",
        "        'Mean_Trainable_Parameters': fold_df['Trainable_Parameters'].mean()\n",
        "    }\n",
        "    # Convert NumPy types in mean_results\n",
        "    mean_results = {k: convert_to_serializable(v) for k, v in mean_results.items()}\n",
        "    with open(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_summary.json', 'w') as f:\n",
        "        json.dump(mean_results, f, indent=4)\n",
        "    fold_df.to_csv(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_results.csv', index=False)\n",
        "    print(\"\\nCross-Validation Summary:\", mean_results)"
      ]
    }
  ]
}