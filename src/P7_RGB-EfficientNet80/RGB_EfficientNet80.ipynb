{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMhzV4K8MQheC/BpUt6EOIa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MRhsci_2Ixs_","executionInfo":{"status":"ok","timestamp":1761342255315,"user_tz":-120,"elapsed":676515,"user":{"displayName":"Now Iknow","userId":"17543420908297692524"}},"outputId":"08a6d923-b793-46e4-bdf1-2346e55ad94e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Dataset Balance: 1211 originals, 1199 recaptures\n","Loading existing train-test split...\n","\n","Training Fold 1/5\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 135ms/step - accuracy: 0.5861 - loss: 0.8436 - val_accuracy: 0.6536 - val_loss: 0.6075\n","Epoch 2/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.7422 - loss: 0.6294 - val_accuracy: 0.7188 - val_loss: 0.5295\n","Epoch 3/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8134 - loss: 0.5235 - val_accuracy: 0.7422 - val_loss: 0.4718\n","Epoch 4/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.8388 - loss: 0.4449 - val_accuracy: 0.8203 - val_loss: 0.4108\n","Epoch 5/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8772 - loss: 0.3736 - val_accuracy: 0.8385 - val_loss: 0.3704\n","Epoch 6/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9069 - loss: 0.2978 - val_accuracy: 0.8620 - val_loss: 0.3268\n","Epoch 7/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9096 - loss: 0.2634 - val_accuracy: 0.8750 - val_loss: 0.2990\n","Epoch 8/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9417 - loss: 0.2115 - val_accuracy: 0.8854 - val_loss: 0.2747\n","Predictions _fold_1: 192 originals, 192 recaptures\n","\n","Training Fold 2/5\n","Epoch 1/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 123ms/step - accuracy: 0.5835 - loss: 0.8329 - val_accuracy: 0.6589 - val_loss: 0.6134\n","Epoch 2/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7433 - loss: 0.6378 - val_accuracy: 0.7161 - val_loss: 0.5478\n","Epoch 3/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8179 - loss: 0.5124 - val_accuracy: 0.7760 - val_loss: 0.4830\n","Epoch 4/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.8802 - loss: 0.4209 - val_accuracy: 0.7995 - val_loss: 0.4437\n","Epoch 5/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8791 - loss: 0.3742 - val_accuracy: 0.8099 - val_loss: 0.4022\n","Epoch 6/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9116 - loss: 0.2921 - val_accuracy: 0.8411 - val_loss: 0.3667\n","Epoch 7/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.9342 - loss: 0.2226 - val_accuracy: 0.8385 - val_loss: 0.3529\n","Epoch 8/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9371 - loss: 0.2012 - val_accuracy: 0.8464 - val_loss: 0.3488\n","Predictions _fold_2: 187 originals, 197 recaptures\n","\n","Training Fold 3/5\n","Epoch 1/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 140ms/step - accuracy: 0.5817 - loss: 0.8262 - val_accuracy: 0.7135 - val_loss: 0.5425\n","Epoch 2/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7340 - loss: 0.6486 - val_accuracy: 0.7578 - val_loss: 0.4693\n","Epoch 3/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8040 - loss: 0.5325 - val_accuracy: 0.7839 - val_loss: 0.4233\n","Epoch 4/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.8540 - loss: 0.4393 - val_accuracy: 0.8255 - val_loss: 0.3849\n","Epoch 5/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.8834 - loss: 0.3601 - val_accuracy: 0.8203 - val_loss: 0.3572\n","Epoch 6/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9150 - loss: 0.3011 - val_accuracy: 0.8385 - val_loss: 0.3558\n","Epoch 7/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.9186 - loss: 0.2676 - val_accuracy: 0.8464 - val_loss: 0.3326\n","Epoch 8/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.9399 - loss: 0.2299 - val_accuracy: 0.8490 - val_loss: 0.3247\n","Predictions _fold_3: 198 originals, 186 recaptures\n","\n","Training Fold 4/5\n","Epoch 1/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.5627 - loss: 0.8168 - val_accuracy: 0.7318 - val_loss: 0.5692\n","Epoch 2/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.7386 - loss: 0.6438 - val_accuracy: 0.7682 - val_loss: 0.4961\n","Epoch 3/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.8302 - loss: 0.5318 - val_accuracy: 0.7943 - val_loss: 0.4407\n","Epoch 4/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8560 - loss: 0.4382 - val_accuracy: 0.8229 - val_loss: 0.4022\n","Epoch 5/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.8716 - loss: 0.3848 - val_accuracy: 0.8385 - val_loss: 0.3550\n","Epoch 6/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9203 - loss: 0.3000 - val_accuracy: 0.8568 - val_loss: 0.3458\n","Epoch 7/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9291 - loss: 0.2557 - val_accuracy: 0.8594 - val_loss: 0.3329\n","Epoch 8/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.9401 - loss: 0.2155 - val_accuracy: 0.8411 - val_loss: 0.3249\n","Predictions _fold_4: 199 originals, 185 recaptures\n","\n","Training Fold 5/5\n","Epoch 1/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 135ms/step - accuracy: 0.5947 - loss: 0.8230 - val_accuracy: 0.7083 - val_loss: 0.5795\n","Epoch 2/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7559 - loss: 0.6305 - val_accuracy: 0.7604 - val_loss: 0.5105\n","Epoch 3/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.8046 - loss: 0.5325 - val_accuracy: 0.7917 - val_loss: 0.4559\n","Epoch 4/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.8579 - loss: 0.4276 - val_accuracy: 0.8203 - val_loss: 0.4041\n","Epoch 5/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.8771 - loss: 0.3756 - val_accuracy: 0.8542 - val_loss: 0.3681\n","Epoch 6/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9099 - loss: 0.2980 - val_accuracy: 0.8594 - val_loss: 0.3436\n","Epoch 7/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.9211 - loss: 0.2459 - val_accuracy: 0.8698 - val_loss: 0.3283\n","Epoch 8/8\n","\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.9389 - loss: 0.2020 - val_accuracy: 0.8698 - val_loss: 0.3264\n","Predictions _fold_5: 193 originals, 191 recaptures\n","\n","Training final model on full training set\n","Epoch 1/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.6006 - loss: 0.8318\n","Epoch 2/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7474 - loss: 0.6131\n","Epoch 3/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8289 - loss: 0.4880\n","Epoch 4/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.8868 - loss: 0.3829\n","Epoch 5/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8997 - loss: 0.3176\n","Epoch 6/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9272 - loss: 0.2668\n","Epoch 7/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9356 - loss: 0.2227\n","Epoch 8/8\n","\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9526 - loss: 0.1793\n","Predictions : 246 originals, 235 recaptures\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final Results for RGB_EfficientNetB0: {'Model': 'RGB_EfficientNetB0', 'Preprocessing': 'RGB', 'Accuracy': 0.8773388773388774, 'Total_Parameters': 4213668, 'Trainable_Parameters': 1515057, 'Fold': 'Final', 'learning_rate': 0.0001, 'batch_size': 16, 'optimizer': 'Adam', 'epochs': 8, 'n_folds': 5, 'dropout_rate': 0.4, 'Precision_originals': 0.8699186991869918, 'Recall_originals': 0.8879668049792531, 'F1-Score_originals': 0.8788501026694046, 'Support_originals': 241.0, 'Precision_recaptured': 0.8851063829787233, 'Recall_recaptured': 0.8666666666666667, 'F1-Score_recaptured': 0.8757894736842106, 'Support_recaptured': 240.0, 'Precision_macro avg': 0.8775125410828576, 'Recall_macro avg': 0.8773167358229599, 'F1-Score_macro avg': 0.8773197881768076, 'Support_macro avg': 481.0, 'Precision_weighted avg': 0.8774967534697684, 'Recall_weighted avg': 0.8773388773388774, 'F1-Score_weighted avg': 0.8773229697038192, 'Support_weighted avg': 481.0}\n","\n","Cross-Validation Summary: {'Model': 'RGB_EfficientNetB0', 'Preprocessing': 'RGB', 'Mean_Accuracy': 0.8583333333333334, 'Std_Accuracy': 0.018652088103614538, 'Mean_Precision_recaptured': 0.8612718347809581, 'Mean_Recall_recaptured': 0.8540303228621291, 'Mean_F1-Score_recaptured': 0.8575225592373658, 'Mean_Total_Parameters': 4213668.0, 'Mean_Trainable_Parameters': 1515057.0}\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from pathlib import Path\n","import json\n","\n","# Step 1: Define paths and hyperparameters\n","DATA_ROOT = \"/content/drive/MyDrive/NTU-Roselab-Dataset\"\n","IMG_SIZE = 224\n","BATCH_SIZE = 16\n","EPOCHS = 8\n","LEARNING_RATE = 1e-4\n","N_FOLDS = 5\n","MODEL_NAME = \"RGB_EfficientNetB0\"\n","OUTPUT_DIR = f\"/content/drive/MyDrive/Recapture_Photo_Detection/{MODEL_NAME}/results\"\n","SPLIT_DIR = \"/content/drive/MyDrive/Recapture_Photo_Detection\"\n","CHECKPOINT_FILE = f\"{OUTPUT_DIR}/checkpoint.json\"\n","PREPROCESSING = \"RGB\"\n","HYPERPARAMETERS = {\n","    \"learning_rate\": LEARNING_RATE,\n","    \"batch_size\": BATCH_SIZE,\n","    \"optimizer\": \"Adam\",\n","    \"epochs\": EPOCHS,\n","    \"n_folds\": N_FOLDS,\n","    \"dropout_rate\": 0.4\n","}\n","\n","# Step 2: Mount Google Drive and verify dataset path\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except ImportError:\n","    raise ImportError(\"This script must be run in Google Colab with Google Drive mounted.\")\n","if not os.path.exists(DATA_ROOT):\n","    raise FileNotFoundError(f\"Dataset directory {DATA_ROOT} does not exist. Please check the path.\")\n","\n","# Step 3: Check dataset balance\n","def check_dataset_balance(data_root):\n","    originals_path = os.path.join(data_root, 'originals')\n","    recaptures_path = os.path.join(data_root, 'recaptures')\n","    originals_count = sum(len(files) for _, _, files in os.walk(originals_path))\n","    recaptures_count = sum(len(files) for _, _, files in os.walk(recaptures_path))\n","    print(f\"Dataset Balance: {originals_count} originals, {recaptures_count} recaptures\")\n","    return originals_count, recaptures_count\n","\n","originals_count, recaptures_count = check_dataset_balance(DATA_ROOT)\n","\n","# Step 4: Define preprocessing function\n","@tf.function\n","def preprocess(img, label):\n","    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img, label\n","\n","# Step 5: Define custom rotation function\n","@tf.function\n","def random_rotation(img, max_angle=0.1):  # max_angle in radians (~10 degrees)\n","    angles = [0, np.pi/2, np.pi, 3*np.pi/2]  # 0°, 90°, 180°, 270°\n","    k = tf.random.uniform(shape=(), minval=0, maxval=len(angles), dtype=tf.int32)\n","    img = tf.image.rot90(img, k)\n","    return img\n","\n","# Step 6: Define data augmentation\n","@tf.function\n","def augment_image(img, label):\n","    img = tf.image.random_flip_left_right(img)\n","    img = random_rotation(img, max_angle=0.1)\n","    return img, label\n","\n","# Step 7: Load or create train-test split\n","def load_or_create_split():\n","    split_files = ['X_train.npy', 'X_test.npy', 'y_train.npy', 'y_test.npy']\n","    if all(os.path.exists(os.path.join(SPLIT_DIR, f)) for f in split_files):\n","        print(\"Loading existing train-test split...\")\n","        X_train = np.load(os.path.join(SPLIT_DIR, 'X_train.npy'))\n","        X_test = np.load(os.path.join(SPLIT_DIR, 'X_test.npy'))\n","        y_train = np.load(os.path.join(SPLIT_DIR, 'y_train.npy'))\n","        y_test = np.load(os.path.join(SPLIT_DIR, 'y_test.npy'))\n","    else:\n","        print(\"Creating new train-test split...\")\n","        dataset = image_dataset_from_directory(\n","            DATA_ROOT,\n","            labels='inferred',\n","            label_mode='binary',\n","            image_size=(IMG_SIZE, IMG_SIZE),\n","            batch_size=BATCH_SIZE,\n","            shuffle=True,\n","            seed=42\n","        )\n","        images, labels = [], []\n","        for img_batch, label_batch in dataset:\n","            images.append(img_batch.numpy())\n","            labels.append(label_batch.numpy())\n","        images = np.concatenate(images, axis=0)\n","        labels = np.concatenate(labels, axis=0).flatten()\n","\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            images, labels, test_size=0.2, stratify=labels, random_state=42\n","        )\n","\n","        Path(SPLIT_DIR).mkdir(parents=True, exist_ok=True)\n","        np.save(os.path.join(SPLIT_DIR, 'X_train.npy'), X_train)\n","        np.save(os.path.join(SPLIT_DIR, 'X_test.npy'), X_test)\n","        np.save(os.path.join(SPLIT_DIR, 'y_train.npy'), y_train)\n","        np.save(os.path.join(SPLIT_DIR, 'y_test.npy'), y_test)\n","\n","    return X_train, X_test, y_train, y_test\n","\n","X_train, X_test, y_train, y_test = load_or_create_split()\n","\n","# Create test dataset\n","test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE).map(preprocess).prefetch(tf.data.AUTOTUNE)\n","\n","# Step 8: Define function to create RGB EfficientNetB0 model\n","def create_model():\n","    input_layer = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='rgb_input')\n","    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n","    for layer in base_model.layers[:-20]:\n","        layer.trainable = False\n","    x = GlobalAveragePooling2D()(base_model(input_layer))\n","    x = Dropout(HYPERPARAMETERS['dropout_rate'])(x)\n","    x = Dense(128, activation='relu')(x)\n","    out = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=input_layer, outputs=out)\n","    model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n","                  loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Step 9: Convert NumPy types to JSON-serializable types\n","def convert_to_serializable(obj):\n","    if isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    return obj\n","\n","# Step 10: Define function to save results\n","def save_model_results(model, dataset, history, model_name, output_dir, fold=None, preprocessing='None', hyperparameters=None):\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","    fold_str = f\"_fold_{fold}\" if fold is not None else \"\"\n","\n","    # Evaluate on dataset\n","    y_true, y_pred = [], []\n","    for imgs, labels in dataset:\n","        preds = (model.predict(imgs, verbose=0) > 0.5).astype(int)\n","        y_true.extend(labels.numpy().astype(int))\n","        y_pred.extend(preds.flatten())\n","\n","    # Check prediction distribution\n","    originals_pred = sum(1 for p in y_pred if p == 0)\n","    recaptures_pred = sum(1 for p in y_pred if p == 1)\n","    print(f\"Predictions {fold_str}: {originals_pred} originals, {recaptures_pred} recaptures\")\n","\n","    # Classification report\n","    class_report = classification_report(y_true, y_pred, target_names=['originals', 'recaptured'], output_dict=True)\n","    class_report_df = pd.DataFrame(class_report).transpose()\n","    class_report_df.to_csv(f'{output_dir}/{model_name}_classification_report{fold_str}.csv')\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['originals', 'recaptured'], yticklabels=['originals', 'recaptured'])\n","    plt.title(f'Confusion Matrix - {model_name}{fold_str}')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.png')\n","    plt.close()\n","\n","    # Save confusion matrix as CSV\n","    cm_df = pd.DataFrame(cm, index=['True_originals', 'True_recaptured'], columns=['Pred_originals', 'Pred_recaptured'])\n","    cm_df.to_csv(f'{output_dir}/{model_name}_confusion_matrix{fold_str}.csv')\n","\n","    # Model summary (only for final model)\n","    if fold is None:\n","        summary_file = f'{output_dir}/{model_name}_summary.txt'\n","        with open(summary_file, 'w') as f:\n","            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    # Calculate total and trainable parameters\n","    total_params = model.count_params()\n","    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n","\n","    # Aggregate results\n","    results = {\n","        'Model': model_name,\n","        'Preprocessing': preprocessing,\n","        'Accuracy': class_report['accuracy'],\n","        'Total_Parameters': total_params,\n","        'Trainable_Parameters': trainable_params,\n","        'Fold': fold if fold is not None else 'Final'\n","    }\n","    if hyperparameters:\n","        results.update(hyperparameters)\n","    for label, metrics in class_report.items():\n","        if isinstance(metrics, dict):\n","            results.update({\n","                f'Precision_{label}': metrics['precision'],\n","                f'Recall_{label}': metrics['recall'],\n","                f'F1-Score_{label}': metrics['f1-score'],\n","                f'Support_{label}': metrics['support']\n","            })\n","\n","    # Convert NumPy types to JSON-serializable types\n","    results = {k: convert_to_serializable(v) for k, v in results.items()}\n","\n","    # Save results to JSON\n","    with open(f'{output_dir}/{model_name}_results{fold_str}.json', 'w') as f:\n","        json.dump(results, f, indent=4)\n","\n","    # Plot and save accuracy/loss curves\n","    if history is not None:\n","        plt.figure(figsize=(10, 4))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(history.history['accuracy'], label='Train Accuracy')\n","        if 'val_accuracy' in history.history:\n","            plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","        plt.title(f'Accuracy Curve - {model_name}{fold_str}')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Accuracy')\n","        plt.legend()\n","        plt.grid(True)\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(history.history['loss'], label='Train Loss')\n","        if 'val_loss' in history.history:\n","            plt.plot(history.history['val_loss'], label='Validation Loss')\n","        plt.title(f'Loss Curve - {model_name}{fold_str}')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.tight_layout()\n","        plt.savefig(f'{output_dir}/{model_name}_accuracy_loss_curve{fold_str}.png')\n","        plt.close()\n","\n","    # Save full model for final model (using .keras format)\n","    if fold is None:\n","        model.save(f'{output_dir}/{model_name}_model.keras', overwrite=True)\n","\n","    return results\n","\n","# Step 11: Checkpointing and resumption logic\n","def load_checkpoint():\n","    if os.path.exists(CHECKPOINT_FILE):\n","        with open(CHECKPOINT_FILE, 'r') as f:\n","            checkpoint = json.load(f)\n","        last_completed_fold = checkpoint.get('last_completed_fold', 0)\n","        print(f\"Resuming from checkpoint: Last completed fold = {last_completed_fold}\")\n","        return last_completed_fold\n","    return 0\n","\n","def save_checkpoint(fold):\n","    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n","    checkpoint = {'last_completed_fold': fold}\n","    with open(CHECKPOINT_FILE, 'w') as f:\n","        json.dump(checkpoint, f, indent=4)\n","\n","# Step 12: Perform 5-fold cross-validation with checkpointing\n","skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n","fold_results = []\n","last_completed_fold = load_checkpoint()\n","\n","for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n","    if fold <= last_completed_fold:\n","        print(f\"Skipping fold {fold} (already completed)\")\n","        # Load results from previous run\n","        fold_str = f\"_fold_{fold}\"\n","        result_file = f'{OUTPUT_DIR}/{MODEL_NAME}_results{fold_str}.json'\n","        if os.path.exists(result_file):\n","            with open(result_file, 'r') as f:\n","                fold_results.append(json.load(f))\n","        continue\n","\n","    print(f\"\\nTraining Fold {fold}/{N_FOLDS}\")\n","\n","    # Create train and validation datasets for this fold\n","    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n","    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n","\n","    train_ds = tf.data.Dataset.from_tensor_slices((X_fold_train, y_fold_train)).batch(BATCH_SIZE).map(preprocess).map(augment_image).prefetch(tf.data.AUTOTUNE)\n","    val_ds = tf.data.Dataset.from_tensor_slices((X_fold_val, y_fold_val)).batch(BATCH_SIZE).map(preprocess).prefetch(tf.data.AUTOTUNE)\n","\n","    # Create model and load weights if available\n","    model = create_model()\n","    fold_str = f\"_fold_{fold}\"\n","    checkpoint_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model{fold_str}.weights.h5'\n","    if os.path.exists(checkpoint_path):\n","        print(f\"Loading weights for fold {fold} from {checkpoint_path}\")\n","        model.load_weights(checkpoint_path)\n","\n","    # Train model with early stopping and checkpointing\n","    checkpoint_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, class_weight={0: 1.0, 1: 1.5}, verbose=1, callbacks=[early_stopping, checkpoint_callback])\n","\n","    # Save results for this fold\n","    results = save_model_results(\n","        model, val_ds, history, MODEL_NAME, OUTPUT_DIR,\n","        fold=fold, preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n","    )\n","    fold_results.append(results)\n","\n","    # Update checkpoint\n","    save_checkpoint(fold)\n","\n","# Step 13: Train final model on full training set if not already done\n","if last_completed_fold < N_FOLDS + 1:\n","    print(\"\\nTraining final model on full training set\")\n","    final_model_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model.keras'\n","    if os.path.exists(final_model_path) and last_completed_fold == 'final':\n","        print(f\"Final model already saved at {final_model_path}, skipping training\")\n","        # Load results from previous run\n","        result_file = f'{OUTPUT_DIR}/{MODEL_NAME}_results.json'\n","        if os.path.exists(result_file):\n","            with open(result_file, 'r') as f:\n","                results = json.load(f)\n","            print(f\"Final Results for {MODEL_NAME}:\", results)\n","    else:\n","        train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE).map(preprocess).map(augment_image).prefetch(tf.data.AUTOTUNE)\n","        model = create_model()\n","        checkpoint_path = f'{OUTPUT_DIR}/{MODEL_NAME}_model.weights.h5'\n","        if os.path.exists(checkpoint_path):\n","            print(f\"Loading weights for final model from {checkpoint_path}\")\n","            model.load_weights(checkpoint_path)\n","\n","        checkpoint_callback = ModelCheckpoint(checkpoint_path, monitor='loss', save_best_only=True, save_weights_only=True)\n","        history = model.fit(train_ds, epochs=EPOCHS, class_weight={0: 1.0, 1: 1.5}, verbose=1, callbacks=[checkpoint_callback])\n","\n","        # Save results for final model\n","        results = save_model_results(\n","            model, test_ds, history, MODEL_NAME, OUTPUT_DIR,\n","            preprocessing=PREPROCESSING, hyperparameters=HYPERPARAMETERS\n","        )\n","        print(f\"Final Results for {MODEL_NAME}:\", results)\n","\n","        # Update checkpoint\n","        save_checkpoint('final')\n","\n","# Step 14: Aggregate cross-validation results\n","if fold_results:\n","    fold_df = pd.DataFrame(fold_results)\n","    mean_results = {\n","        'Model': MODEL_NAME,\n","        'Preprocessing': PREPROCESSING,\n","        'Mean_Accuracy': fold_df['Accuracy'].mean(),\n","        'Std_Accuracy': fold_df['Accuracy'].std(),\n","        'Mean_Precision_recaptured': fold_df['Precision_recaptured'].mean(),\n","        'Mean_Recall_recaptured': fold_df['Recall_recaptured'].mean(),\n","        'Mean_F1-Score_recaptured': fold_df['F1-Score_recaptured'].mean(),\n","        'Mean_Total_Parameters': fold_df['Total_Parameters'].mean(),\n","        'Mean_Trainable_Parameters': fold_df['Trainable_Parameters'].mean()\n","    }\n","    # Convert NumPy types in mean_results\n","    mean_results = {k: convert_to_serializable(v) for k, v in mean_results.items()}\n","    with open(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_summary.json', 'w') as f:\n","        json.dump(mean_results, f, indent=4)\n","    fold_df.to_csv(f'{OUTPUT_DIR}/{MODEL_NAME}_cv_results.csv', index=False)\n","    print(\"\\nCross-Validation Summary:\", mean_results)"]}]}