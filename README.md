# ğŸŒ Image Recapture Detection

## ğŸ’¡ Introduction

This project studies how to tell if an image is **original** or a **recaptured photo**.
A recaptured image is a photo taken of a **digital screen** such as a **laptop, tablet, or smartphone**.
The goal is to detect small visual clues that show whether an image was taken from a screen or is an original digital file.

---

## ğŸ” What is Recapture Detection

Recapture detection helps computers find out if a photo was taken from another screen.
When a person takes a picture of a monitor, tiny marks appear because of **screen pixels**, **light reflections**, or **camera focus**.
These small changes help identify a recaptured image.

---

## ğŸ”’ Why It Is Important

1ï¸âƒ£ Helps prevent the stealing of important digital data.
2ï¸âƒ£ Useful in finding **fake screenshots** or **fake ID photos**.
3ï¸âƒ£ Supports **digital security** and **forensic investigations**.

---

## ğŸ“š Papers Studied

Before building the models, six main research papers were reviewed.
Each used different ideas like **chromaticity maps**, **adversarial learning**, and **attention networks**.
These papers helped decide the right direction for this project.

### Main Ideas from the Papers

âœ¨ Studying how colors change when screens are photographed.
âœ¨ Using neural networks that can tell clean and recaptured images apart.
âœ¨ Observing light reflections and pixel patterns.
âœ¨ Mixing local and global details for better results.

---

## ğŸ§  Technical Words Explained

ğŸ **MoirÃ© Pattern** â€“ Wavy lines that appear when a screen is photographed.

ğŸ¨ **Color Artifacts** â€“ Unnatural colors near edges in screen photos.

ğŸ”Š **Fourier Transform** â€“ Looks at frequency patterns in an image.

âœ‚ï¸ **Laplacian Filter** â€“ Highlights edges and small details.

ğŸ” **Transfer Learning** â€“ Using a pre-trained model to improve accuracy and save time.

---

## âš™ï¸ Method Used

### ğŸ”¸ Step 1: Image Feature Extraction

Two image processing methods were used:

ğŸ“ˆ **Fourier Transform**

* Changes the image into frequency form.
* Finds repeating patterns like moirÃ© lines.

ğŸ§© **Laplacian Filter**

* Detects edges and fine details.
* Helps find blur and unnatural sharpness from screen photos.

---

### ğŸ”¸ Step 2: Custom CNN Model

A simple **Convolutional Neural Network (CNN)** was built to classify images as *original* or *recaptured*.
It includes:

* Four convolution layers
* Global average pooling
* Batch normalization
* Dropout for regularization
* Dense output layer with sigmoid activation

This model is lightweight and easy to train on medium datasets.

---

### ğŸ”¸ Step 3: Transfer Learning Models

Two advanced models were also used to improve accuracy.

ğŸ“± **MobileNetV2**

* Fast and small model.
* Works well with limited data.
* Suitable for real-world mobile applications.

âš¡ **EfficientNet**

* High accuracy with fewer parameters.
* Keeps fine image textures.
* Great for detailed recapture detection tasks.

---

## ğŸ§ª Experiments Conducted

Eleven experiments were done using different models, datasets, and preprocessing combinations:

1ï¸âƒ£ Basic image analysis and preprocessing

2ï¸âƒ£ CNN on Fourier images

3ï¸âƒ£ MobileNetV2 on Fourier images

4ï¸âƒ£ MobileNetV2 on Laplacian images

5ï¸âƒ£ MobileNetV2 on both Fourier and Laplacian images

6ï¸âƒ£ MobileNetV2 on RGB (normal) images

7ï¸âƒ£ EfficientNet on RGB images

8ï¸âƒ£ EfficientNet on both Laplacian and RGB images

9ï¸âƒ£ RGB-EfficientNetB0-Laplacian (Roselab + Android-captured)

ğŸ”Ÿ RGB-EfficientNetB0 (Roselab + Android-captured)

1ï¸âƒ£1ï¸âƒ£ RGB-EfficientNetB0 (NTU-Android x8) + Testing on iPhone

---

## ğŸ“Š Results

ğŸ¥‡ **RGB-EfficientNetB0 (NTU-Android x8) + iPhone test** â€” **92% Accuracy**  
â­ New best model with excellent balance and real-world generalization  
â­ Precision 0.92 | Recall 0.92 | F1 0.92  
â­ Works reliably on both Android-captured and iPhone test images  

ğŸ¥ˆ **RGB + Laplacian EfficientNetB0** â€” 90% Accuracy  
â­ Best overall model with balanced precision and recall  
â­ Combines both RGB and Laplacian image inputs  
â­ High accuracy but uses more parameters (8.4M)

ğŸ¥‰ **RGB EfficientNetB0** â€” 87.7% Accuracy  
â­ Strong single-stream model using only RGB images  
â­ Balanced performance and lower complexity

4ï¸âƒ£ **RGB MobileNetV2** â€” 85.7% Accuracy  
â­ Very lightweight model  
â­ Ideal for mobile or real-time use

5ï¸âƒ£ **Laplacian MobileNetV2** â€” 84.6% Accuracy  
â­ Uses only edge information  
â­ Most efficient model for low-resource systems

ğŸš€ Live Demo
Try it here: https://huggingface.co/spaces/UzerDeveloper07/screen-recapture-detection
